
<!DOCTYPE html>
<html lang="en">



  <head>
    <style>
      .centered {
            display: flex;
            align-items: center;
            justify-content: center;
            text-align: center;
            line-height: 1.2;
            /* width: 60%; */
        }
        .centered img {
            margin-right: 10px;

        }
        .left-align {
            text-align: left;
            /* width: 60%; */
        }
      body {
          font-family: Arial, sans-serif;
          background-color: #f5f5f5;
          color: #333;
          margin: 0;
          padding: 20px;

      }
      .paper {
          margin-bottom: 20px;
          background-color: #f9f9f9; /* 浅灰色背景 */
          border: 1px solid #ddd;
          border-radius: 5px;
          padding: 20px;
          box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
          
      }
      .new_h3{
        color: #5c6bc0;
      }
      .paper h2 {
          font-size: 24px;
          font-weight: bold;
          margin-bottom: 10px;
          color: #5c6bc0; /* 柔和的蓝紫色 */
      }
      .paper p {
          font-size: 16px;
          line-height: 1.5;
          color: #666; /* 柔和的灰色 */
      }
      .paper a {
          color: #5c6bc0; /* 柔和的蓝紫色 */
          text-decoration: none;
          transition: color 0.3s ease;
      }
      .paper a:hover {
          color: #3949ab; /* 柔和的深蓝色 */
          text-decoration: underline;
      }
  </style>

    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="./pic/output.png" type="image/x-icon">
    <title>
      Bi-JROS:Bi-level Learning of Task-Specific Decoders for Joint Registration and One-Shot Medical Image Segmentation
    </title>
    <!-- Bootstrap -->
    <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <!-- <link href='http://fonts.googleapis.com/css?family=Open+Sans:400italic,700italic,800italic,400,700,800' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="css/project.css" media="screen" />
    <link rel="stylesheet" type="text/css" media="screen" href="css/iconize.css" />
    <script src="js/google-code-prettify/prettify.js"></script> -->
  </head>

  <!-- cover -->
  <section>
    <div class="jumbotron text-center mt-0">
      <div class="container">
        <div class="row">
          <div class="col-12">
            
            <h2 class="centered">
              <img src="./pic/logo1.ico" alt="" width="100" height="100">
              <!-- <img src="./pic/logo_2.png" alt="" width="100" height="100"> -->
              <div>
                  Bi-level Learning of Task-Specific Decoders for <br>
                  Joint Registration and One-Shot Medical Image Segmentation
              </div>
          </h2>
            <h4 style="color:#FFA500;">CVPR 2024</h4>
            <hr>
            <h6>
                <a href="https://scholar.google.com/citations?user=vLN1njoAAAAJ&hl=zh-CN&oi=ao" target="_blank">Xin Fan</a><sup>1*</sup>,
                <a >Xiaolin Wang</a><sup>1*</sup>,
                <a href="https://scholar.google.com/citations?user=MWPKMlsAAAAJ&hl=zh-CN&oi=ao" target="_blank">Jiaxin Gao</a><sup>1</sup>,
                <a href="https://scholar.google.com/citations?user=UNXTe-4AAAAJ&hl=zh-CN" target="_blank">Jia Wang</a><sup>1</sup>,
                <a  target="_blank">Zhongxuan Luo</a><sup>1</sup>,
                <a target="_blank">Risheng Liu</a><sup>1</sup>,

              </h6>
            <p>
                <sup>1</sup>School of Software Technology, Dalian University of Technology, Dalian, China &nbsp;&nbsp;
                <!-- <sup>2</sup>Centre for Artificial Intelligence and Robotics, Hong Kong &nbsp;&nbsp; -->
            </p>

            <div class="row justify-content-center">
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://openaccess.thecvf.com/content/CVPR2024/html/Fan_Bi-level_Learning_of_Task-Specific_Decoders_for_Joint_Registration_and_One-Shot_CVPR_2024_paper.html" role="button"  target="_blank">
                    <i class="fa fa-file"></i> Paper</a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/Coradlut/Bi-JROS" role="button"  target="_blank">
                    <i class="fa fa-github-alt"></i> Code </a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="#bib" role="button"  target="_blank">
                    <i class="fa fa-database"></i> BibTex </a> </p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- abstract -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Abstract</h3>
            <hr style="margin-top:0px">
            <!-- <h6 style="color:#8899a5">  -->
              <!-- SyncDreamer is able to directly generate multiview consistent images, which allows 3D reconstruction by NeuS or NeRF without SDS loss.  -->
              <!-- TL;DR:<i>Endora</i> enables the <b>high-fidelity medical video generation</b> on endoscopy scenes and demonstrates the <b>versatile ability through successful applications</b> in video-based disease diagnosis and 3D surgical scene reconstruction. -->
            <!-- </h6> -->

              <!-- <video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="video/teaser.mp4" type="video/mp4">
              </video> -->



          <p class="text-left">
            <!-- U-Net has become a cornerstone in various visual applications such as image segmentation and diffusion probability models. 
  
            While numerous innovative designs and improvements have been introduced by incorporating transformers or MLPs, the networks are still limited to linearly modeling patterns as well as the deficient interpretability. To address these challenges, our intuition is inspired by the impressive results of the Kolmogorov-Arnold Networks (KANs) in terms of
            accuracy and interpretability, which reshape the neural network learning via the
            stack of non-linear learnable activation functions derived from the Kolmogorov-
            Anold representation theorem. 
           
            Specifically, in this paper, we explore the untapped
            potential of KANs in improving backbones for vision tasks. 
            
            We investigate, modify and re-design the established U-Net pipeline by integrating the dedicated KAN
            layers on the tokenized intermediate representation, termed U-KAN. Rigorous medical image segmentation benchmarks verify the superiority of U-KAN by higher
            accuracy even with less computation cost. 
           
           
            We further delved into the potential of U-KAN as an alternative U-Net noise predictor in diffusion models, demonstrating
            its applicability in generating task-oriented model architectures. 
           
            These endeavours unveil valuable insights and sheds light on the prospect that with U-KAN, you can
            make strong backbone for medical image segmentation and generation. -->

            One-shot medical image segmentation (MIS) aims to cope with the expensive, time-consuming, and inherent hu-man bias annotations. 
            One prevalent method to address one-shot MIS is joint registration and segmentation (JRS)with a shared encoder, which mainly explores the voxel-wise correspondence between the labeled data and unlabeled data for better segmentation. 
            However, this method omits underlying connections between task-specifc decoders for segmentation and registration, leading to unstable train-ing. 
            In this paper, we propose a novel Bi-level Learning of Task-Specifc Decoders for one-shot MIS, employing a pretrained fxed shared encoder that is proved to be more quickly adapted to brand-new datasets than existing JRS without fxed shared encoder paradigm. 
            To be more spe-cifc, we introduce a bi-level optimization training strategy considering registration as a major objective and segmenta-tion as a learnable constraint by leveraging inter-task cou-pling dependencies. 
            Furthermore, we design an appear-ance conformity constraint strategy that learns the back-ward transformations generating the fake labeled data used to perform data augmentation instead of the labeled image,to avoid performance degradation caused by inconsistent styles between unlabeled data and labeled data in previ-ous methods.
            Extensive experiments on the brain MRI task across ABIDE, ADNI, and PPMI datasets demonstrate that the proposed Bi-JROS outperforms state-of-the-art one-shot MIS methods for both segmentation and registration tasks.
          
          
          </p>

        <p class="text-center">
          <!-- Reverse process of SyncDreamer's multiview diffusion. -->
          <!-- Sampled realistic endoscopy videos by <i>Endora</i>.  -->
        </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Highlight</h3>
            <hr style="margin-top:0px">
            <!-- <h6 style="color:#8899a5">  -->
              <!-- SyncDreamer is able to directly generate multiview consistent images, which allows 3D reconstruction by NeuS or NeRF without SDS loss.  -->
              <!-- TL;DR:<i>Endora</i> enables the <b>high-fidelity medical video generation</b> on endoscopy scenes and demonstrates the <b>versatile ability through successful applications</b> in video-based disease diagnosis and 3D surgical scene reconstruction. -->
            <!-- </h6> -->

              <!-- <video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="video/teaser.mp4" type="video/mp4">
              </video> -->

          <p class="text-left">
            <ul style="list-style-position: inside; text-align: left; margin-left: 0x;">
              <li>We propose a Bi-level optimization-based framework for
                Joint registration and One-shot Segmentation, termed
                as Bi-JROS, which precisely characterizes the coupling
                constraints between decoders specifc to registration and
                segmentation tasks.</li>
              
              <li>
                We design an iterative Gradient Response (GR) algo-
                rithm to tackle the nested bi-level optimization challenge.
                It leverages the gradient response of the segmentation
                decoder to the registration decoder during each step of
                the optimization process, ensuring more effective and
                stable training compared to simple alternating learning
                strategy.
              </li>
             
              <li>
                We propose an Appearance Conformity Constraint
                (ACC) to avoid the texture gap between target and atlas
                images and increase the diversity of the data. This is inte-
                grated into the segmentation task to strengthen the inter-
                connection between registration and segmentation.
              </li>
              <!-- <li>
              The application of U-KAN to existing diffusion models as an improved noise predictor demonstrates  its potential in backboning generative tasks and broader vision settings.
              </li> -->


            </ul>
         
          
          </p>

        <p class="text-center">
          <!-- Reverse process of SyncDreamer's multiview diffusion. -->
          <!-- Sampled realistic endoscopy videos by <i>Endora</i>.  -->
        </p>
        </div>
      </div>
    </div>
  </section>
  <br>
  

  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h2>Network</h2>
            <hr style="margin-top:0px">
            <img src="./pic/framework.jpg" alt="" width="1000" height="600">
            <br>
            <br>
            <div class="text-left">
              Overall framework of the proposed Bi-JROS. (a) demonstrates the pretraining process of the shared encoder, (b) and (c) together constitute the bi-level optimization learning phase and (d) illustrates the mechanism of gradient updating.
            <div>
      </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h2>Segmentation Bi-JROS </h2>
            <hr style="margin-top:0px">
            <h3 class="new_h3"> Qualitative Results </h3>
            <img src="./pic/seg.jpg" alt="" width="1000" height="500">
            <h3 class="new_h3"> Quantitative Results </h3>
            <img src="./pic/res_1.png" alt="" width="800" height="250">
            
      </div>
    </div>
  </section>
  <br>
  
  <section>
    <div class="container"> 
      <div class="row">
        <div class="col-12 text-center">
            <h2>Diffusion U-KAN</h2>
            <hr style="margin-top:0px">
            <h3 class="new_h3"> Qualitative Results </h3>
            <img src="./pic/gen.jpg" alt="" width="800" height="600">
            <h3 class="new_h3"> Quantitative Results </h3>
            <img src="./pic/res_2.png" alt="" width="800" height="200">

    </div>
  </div>
</section>
<br>

  
  

<!--   
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h2>More results</h2>
            <hr style="margin-top:0px">
            <video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="video/more_results.mp4" type="video/mp4">
            </video>

          <p class="text-center">
              Test images are downloaded from the Internet and some of them are from <a href="https://wiki.biligame.com/ys/%E9%A6%96%E9%A1%B5" target="_blank">Genshin Impact Wiki</a>.
          </p>
        </div>
      </div>
    </div>
  </section>
  <br> -->

  <!-- citing -->
  <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Citation</h3>
          <hr style="margin-top:0px">
              <pre style="background-color: #D0DBEF;padding: 1.25em 1.5em">
<code id="bib">@inproceedings{fan2024bi,
  title={Bi-level learning of task-specific decoders for joint registration and one-shot medical image segmentation},
  author={Fan, Xin and Wang, Xiaolin and Gao, Jiaxin and Wang, Jia and Luo, Zhongxuan and Liu, Risheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11726--11735},
  year={2024}
}</code>
              </pre>
          <hr>
      </div>
    </div>
  </div>

  <!-- citing
  <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Citation</h3>
          <hr style="margin-top:0px">
              <pre style="background-color: #87CEFA;padding: 1.25em 1.5em">
                <code>@article{li2024u,
                      title={U-KAN Makes Strong Backbone for Medical Image Segmentation and Generation},
                      author={Li, Chenxin and Liu, Xinyu and Li, Wuyang and Wang, Cheng and Liu, Hengyu and Yuan, Yixuan},
                      journal={arXiv preprint arXiv:2406.02918},
                      year={2024}
                    }
                  } </code>
              </pre>
          <hr>
      </div>
    </div>
  </div> -->



  <footer class="text-center" style="margin-bottom:10px">
      Modified from <a href="https://yes-u-kan.github.io/" target="_blank">this website</a>
  </footer>

</body>
</html>
